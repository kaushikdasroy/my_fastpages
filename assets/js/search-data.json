{
  
    
        "post0": {
            "title": "Malaria Classification Pipeline Of Microscopy Slides",
            "content": "Malaria Classification model execution in Nvidia Clara deploy . This is not for clinical use and should NOT be used for diagnostics purposes. . I will be using the Nvidia Clara Deploy to run a Nvidia GPU Cloud(NGC) model for classification of malaria in microscopy slides converted into png files. . The docker container for the model is in https://ngc.nvidia.com/catalog/containers/nvidia:clara:ai-malaria . As per above url, The network architecture used to train this model is based on the 2015 academic publication “Deep Residual Learning for Image Recognition” by He et. al. . I will be following this link to run a clara pipeline to classify microscopy slides. https://ngc.nvidia.com/catalog/resources/nvidia:clara:clara_ai_malaria_pipeline . I will use a clara deploy SDK running on AWS g4dn.xlarge instance. The description of how to install clara deploy on an AWS instance is in another post. . My running clara instance as shown by the running helm charts . . Create a pipeline directory if you don’t have it already . mkdir -p ~/.clara/pipelines . . Make sure you are connected to nvcr.io . . Pull the malaria classification pipeline . . Inspect the directory and unzip the input file to get the input images . . This will create an input directory containing the png images to be classified . . Unzip the model and related files in a common model directory. Create the /clara/common/models directory if you don’t have it created already . . Create a pipeline utilizing the pipeline yaml file given. Inspect the pipeline yaml file, which builds a docker container as given in https://ngc.nvidia.com/catalog/containers/nvidia:clara:ai-malaria . . Create a pipeline job for the pipeline we just created utilizing the input images to be classified as input . clara create jobs -n malaria-test -p 8f315a0453c6416bbca18bdff457ee26 -f ~/.clara/pipelines/clara_ai_malaria_pipeline/input/png . . Start the job . . Check the job status in Clara console using localhost:32002 . . You may download the output to look at the classified images locally. A stamp on the left corner of the classified out images will indicate a true (`T’) or false (`F`) classification for malaria. . . . You may also use Clara download to download the output in a directory . clara download 602d2d58adbe4476918d9fd73daa7768:/operators/ai-app-malaria/* /etc/clara/experiments/covidtest . . . Use `eog` to look at the output inference files . . . There you have it malaria inference using Clara deploy pipeline .",
            "url": "https://blog.uplandr.com/2021/09/16/Malaria-Classification-Pipeline-of-Microscopy-Slides.html",
            "relUrl": "/2021/09/16/Malaria-Classification-Pipeline-of-Microscopy-Slides.html",
            "date": " • Sep 16, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Brain Tumor Segmentation Model Implementation In Clara Deploy",
            "content": "Brain Tumor Segmentation with Clara Deploy Pipeline . We will use the installed Clara deploy SDK (refer to previous posts to install Clara Deploy in AWS) to run a brain tumor segmentation pipeline. We will use the clara ngc segmentation model for this purpose (ref - https://ngc.nvidia.com/catalog/resources/nvidia:clara:clara_ai_brain_tumor_pipeline) . Create a pipeline folder and pull the pipeline from ngc . clara pull pipeline clara_ai_brain_tumor_pipeline . . Unzip the input dicom series . . Unzip the model . . Register the model . clara create model -p segmentation_mri_brain_tumors_br16_t1c2tc_v1/ -t tensorflow . . Create the pipeline . clara create pipeline -p brain-tumor-pipeline-model-repo.yaml . . Create and start the job . clara create jobs -n brain-test -p b8703c88407848a48a58496ef411daee -f ~/.clara/pipelines/clara_ai_brain_tumor_pipeline/dcm . . Check the Clara Console in localhost:32002 and take the output download of the job. . . View the output in 3d-slicer-segmented tumor . . Location of the tumor through rendering . .",
            "url": "https://blog.uplandr.com/2021/09/15/Brain-Tumor-Segmentation-Model-Implementation-in-Clara-Deploy.html",
            "relUrl": "/2021/09/15/Brain-Tumor-Segmentation-Model-Implementation-in-Clara-Deploy.html",
            "date": " • Sep 15, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Clara Deploy Installation Using Ansible",
            "content": "Clara Deploy installation using Ansible in an Ubuntu 18.04 . Here we are going to set up Clara Deploy in Ubuntu 18.04. This setup can be used for creating clara pipeline for various use cases. The ubuntu server will host the Ansible as well, we are not remoting into the server. . For this I will be using following resource from NVIDIA . https://ngc.nvidia.com/catalog/resources/nvidia:clara:clara_ansible . And following resource from ansible . https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html . Create a g4dn ubuntu 18.04 instance in AWS . . My system has python3 installed . Get the clara deploy ansible installation download from . wget –content-disposition https://api.ngc.nvidia.com/v2/resources/nvidia/clara/clara_ansible/versions/0.8.1-2108.1/zip -O clara_ansible_0.8.1-2108.1.zip . . Unzip the files to get the ansible `playbook` folder. Install unzip with `sudo install unzip` if required. . . My system doesn’t have Ansible installed. We can install ansible using `pip`. We can follow this process outlines in https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html . to install Ansible with pip. . My system doesn’t have a `pip` either. Let’s start by installing pip. . $ curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py . . You may have to install python disutils to install additional python utilities like pip. You can do that my sudo apt-get install python3-distutils . Also install python-apt with . sudo apt-get install python3-apt . Then we can install pip . python3 get-pip.py –user . . Go ahead installing ansible . python3 -m pip install –user ansible . . Make sure to add ansible in $PATH . . Start installing NVIDIA drive from playbook . . I changed the hostname to localhost as I am using the local machine for clara deploy . Do a reboot with . Sudo reboot now . Start installing clara with . Ansible-playbook -K clara.yml . . Clara is installed. Check the version to ensure. . .",
            "url": "https://blog.uplandr.com/2021/09/11/Clara-Deploy-Installation-using-Ansible.html",
            "relUrl": "/2021/09/11/Clara-Deploy-Installation-using-Ansible.html",
            "date": " • Sep 11, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Nvidia Clara On Triton Inference Server For Xray Inference",
            "content": "Inference using AI Model . Let’s start clara back up again. . . Deployed kubernetes pods . . Setting up TRITON inference server to host our model . Create a folder structure as below . . Move the refined model we created before to this directory. . . Refer: https://blog.uplandr.com/2021/09/02/Fine-tune-a-Chest-Xray-Classification-Model-using-NVIDIA-Clara-Train.html . Refer to this documentation to know about the directory structure: https://docs.nvidia.com/deeplearning/triton-inference-server/master-user-guide/ . Create a file as below: . . Create another file with our labels . . Create a Clara Deploy Operator . We will create a clara deploy operator. This operator will be running in a container independent of clara deploy and the operator can be made part of a deployment pipeline. . Steps are given in here - https://ngc.nvidia.com/catalog/containers/nvidia:clara:app_base_inference . We need to grab these- . Clara deploy base inference operator . | Clara chest classification operator . | TRITIS (Triton) container . | . Make sure you have your ngc connection or else rebuild connection to ngc with docker login nvcr.io . . . . Retag the docker image as latest . . Create a Operator directory structure . . Run the chest xray operator docker container . . Copy 2 files from the container . . . Exit from the container and change the owner for the files to your own. There are few changes to be made in these two files. Change the model to be used to “classification_covidxray_v1” from “classification_cheastxray_v1”. And in the config_inference change the `subtrahend` and `divisor` to 128. . . Create a Dockerfile with base as app_base_inference and copy the config files taken from the chestxray . . Test the custom operator . We will run the operator outside of clara deploy pipeline using docker and a script. . Copy the script from the “executing with docker” section of the link - https://ngc.nvidia.com/catalog/containers/nvidia:clara:app_base_inference . Change the script as follows to make it suitable for our purpose. . Create a file . vi /etc/clara/operators/run_covid_docker.sh . Open the file run_covid_docker.sh and paste the script from “executing with docker” section of the link - https://ngc.nvidia.com/catalog/containers/nvidia:clara:app_base_inference . Need to make following edits: . Replace APP_NAME with “app_covidxray” . Replace MODEL_NAME with “classification_covidxray_v1”. . The line that starts with nvidia-docker — replace $(pwd) with clara/common (so this part reads -v /clara/common/models/${MODEL_NAME}:/models/${MODEL_NAME} . In the line “-v $(pwd)/input:/input ”, replace $(pwd) with “/etc/clara/operators/app_covidxray” . In the line “-v $(pwd)/output:/output ”, replace $(pwd) with “/etc/clara/operators/app_covidxray” . In the line “-v $(pwd)/logs:/logs ”, replace $(pwd) with “/etc/clara/operators/app_covidxray” . In the line “-v $(pwd)/publish:/publish ”, replace $(pwd) with “/etc/clara/operators/app_covidxray” . Comment the lines as indicated in notes of the file if using NGC containers for testing. . Save and exit from the file. . Copy one image in our test input folder. . cp /etc/clara/experiments/covid-training-set/training-images/1-s2.0-S0929664620300449-gr2_lrg-b.png /etc/clara/operators/app_covidxray/input . Change permission of the script file and run the script . chmod 700 /etc/clara/operators/run_covid_docker.sh . cd /etc/clara/operators/ . . To check the job was successful, check the output folder for a file with the inference . . Check the output folder and display the image with labels and categories and % of chance . . Output with inference shown in the picture! . .",
            "url": "https://blog.uplandr.com/2021/09/09/NVIDIA-Clara-on-Triton-Inference-Server-for-Xray-Inference.html",
            "relUrl": "/2021/09/09/NVIDIA-Clara-on-Triton-Inference-Server-for-Xray-Inference.html",
            "date": " • Sep 9, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Fine Tune A Chest Xray Classification Model Using Nvidia Clara Train",
            "content": "Training with NVIDIA Clara Train . In this section, you will fine tune a pretrained model with your own data. This model then can be used for inference. Disclaimer - This model is not for clinical use and models are not fit for clinical decision making. . For setting up Clara Train SDK refer to - https://blog.uplandr.com/2021/08/29/Setup-NVIDIA-Clara-Train-Medical-Image.html . I am referring to - https://medium.com/@integratorbrad/how-i-built-a-space-to-train-and-infer-on-medical-imaging-ai-models-part-9-26bbaae9ca2f . And few other sources. . Prepare the training data . For this exercise we will be using training images from https://github.com/ieee8023/covid-chestxray-dataset . Download the repository to ~/Downloads folder . . Unzip the file in the experiments folder . . The contents of the folder . . Install few libraries for python coding to cleanup the input images: . . . . . . Create a folder for storing training images . . Installed sublime text 3 editor for source code creation. . https://linuxize.com/post/how-to-install-sublime-text-3-on-ubuntu-18-04/ . . . Start sublime . . Create convert.py python file for processing the images . . . Run the script to process the files . . Next up, create a json file with image and finding. . Taking the metadata.csv file and cleaning it up to create a datalist.json file. . . . In this process removed some training data with biases or with unique findings with very few data points. . Used xl to open the csv and sort/filter/remove etc as required. . Use https://jsonlint.com/ to check the json for correctness. . Replace all the reference of .jpeg and .jpg to .png in the datalist.json file. . . Take one or two of the images out of the json for running an inference on it later . . . Training the model . Training needs GPU resources and stopping clara deploy will help. . . . Get inside Clara Train container. *Correction* use clara-train-sdk:v3:0 in place of v4. The model I am going to download works with V3 (Tensorflow version of clara). From V4 Clara moved to pytorch. . . Download the chest xray model (MMAR) . . As you can the /clara/experiments folders are mapping inside the Clara Train container . . Lets clone the MMAR to host . . Some cleanup . . Run the following in a separate terminal to give permission. Close the terminal after done. . . Change some of the training script in the train_finetune.sh . . Changing 3 data points 1) json source 2) epoch count(to 500) and 3) Learning Rate (to 0.00002) . Change training configuration . . There are 6 things we are going to change- . After: . 1) Changed epoch to 500, 2) learning rate to 2e-5, 3)Update the “subtrahend” and “divisor” parameters from the CenterData transform, in both the “train” and “validate” sections, 4) &amp; 5) Change image_pipeline name to ClassificationKerasImagePipeline and added “sampling” : “automatic” in training (not in validation), 6) computeAUC aligned with 6 categories . Make #3 and #6 changes in the validation configuration file . . Make following changes to environment configuration. Changes are 1) data_root and 2) dataset_json . Lets begin fine-tuning the model! . Start by making the script executable . . *correction* . Datalist.json file should be in this location - /workspace/data/covid-training-set/training-images/ . Else will get this error! . . Few other errors may arise; fix these with data cleanup or delete. . After this, training will start . . . Now the training is complete. . . As you can see the best metrics was at epoch 570 with validation metric of 0.83 . Get inside docker container if you came out . . See tensorboard output . . . Export the model . . . Exit from the docker container and check the model we trained . . Models are listed . . So we have fine-tuned a model that is trained on the data we created! awesome. .",
            "url": "https://blog.uplandr.com/2021/09/02/Fine-tune-a-Chest-Xray-Classification-Model-using-NVIDIA-Clara-Train.html",
            "relUrl": "/2021/09/02/Fine-tune-a-Chest-Xray-Classification-Model-using-NVIDIA-Clara-Train.html",
            "date": " • Sep 2, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Setup Nvidia Clara Deploy For Medical Image Inference",
            "content": "In this post I will go through the process of setting up NVIDIA Clara Deploy on AWS . I am referring to Brad Genereaux’s blog post to create a NVIDIA Clara based system. I will also use the NVIDIA Clara official installation guide and various other posts to install and troubleshoot. . Brad’s blog - https://medium.com/@integratorbrad/how-i-built-a-space-to-train-and-infer-on-medical-imaging-ai-models-part-1-24ec784edb62 . Disclaimer: The example shown here is NOT FOR CLINICAL USE and learning purpose only. The models are not FDA approved and not to be used for clinical decision making. . If you have an environment setup with ubuntu, docker, CUDA, NVIDIA container toolkit, NGC access then start from ‘Setting up inference environment (Clara Deploy)’ section. . AWS Environment setup . Create an AWS instance with following configuration (taken from NVIDIA official guide): . . Ref: https://docs.nvidia.com/clara/deploy/ClaraInstallation.html#installation-on-a-cloud-service-provider-csp . I will create a spot instance for my environment. P3.8xlarge is an expensive environment, by using a spot instance you can reduce the cost significantly, but it will create some interruption based on spot availability. . You might be ok with using some inexpensive GPU instances like g4dn, but for now I am going with NVIDIA suggested instance(p3) . After creating the spot instance, remote into the AWS server - . . Check that you have a CUDA enabled GPU: . . If nothing comes back from lspci command, then update the PCI hardware database of linux by entering `update-pciids` command and rerun the lspci | grep command. | . Check for the CUDA supported version of linux: . . It is a 64-bit system! . Verify that gcc is installed . . Find out the kernel version of the system . . Before installing CUDA, the kernel header and development package of the same kernel version need to be installed. . . Install CUDA by going to this link and selecting right choices: . https://developer.nvidia.com/cuda-downloads?target_os=Linux . . Reboot the system after you are done with the above steps . . Install Docker . Follow the steps outlined in https://docs.docker.com/engine/install/ubuntu/ . . . Add docker’s official GPG Key . curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg –dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg | . Setup stable repository . echo . “deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu . $(lsb_release -cs) stable” | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null | . Update apt package index . sudo apt-get update . Install docker community edition . sudo apt-get install docker-ce=5:19.03.8~3-0~ubuntu-bionic docker-ce-cli=5:19.03.8~3-0~ubuntu-bionic containerd.io . Verify that Docker is installed . sudo docker run hello-world . Add your user id in Docker user group . sudo usermod -aG docker $USER . Reboot . Sudo reboot now . Install NVIDIA container toolkit . Follow the steps outlined here - . https://github.com/NVIDIA/nvidia-docker . https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker . Setup the stable repository and the GPG key- . distribution=$(. /etc/os-release;echo $ID$VERSION_ID) . &amp;&amp; curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - | . &amp;&amp; curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list | . After updating the package list install the nvidia-docker2 . sudo apt-get update &amp;&amp; sudo apt-get install -y nvidia-docker2 . Restart docker demon . sudo systemctl restart docker . Test by running a base CUDA container . sudo docker run –rm –gpus all nvidia/cuda:11.0-base nvidia-smi . . Configuration of NGC access . Login to NGC (https://ngc.nvidia.com/) and generate API Key and execute the following . mkdir /etc/clara/ngc . cd /etc/clara/ngc . wget https://ngc.nvidia.com/downloads/ngccli_cat_linux.zip &amp;&amp; unzip ngccli_cat_linux.zip &amp;&amp; rm ngccli_cat_linux.zip ngc.md5 &amp;&amp; chmod u+x ngc . Add NGC key in ngc config . ./ngc config set . . Config docker to use NGC token . docker login nvcr.io . . Now Ubuntu is loaded with Docker, NVIDIA docker, NVIDIA container toolkit . Setting up inference environment (Clara Deploy) . Disclaimer: The example shown here is NOT FOR CLINICAL USE and learning purpose only. The models are not FDA approved and not to be used for clinical decision making. . Clara Deploy installation guide is available in nvidia official site - https://docs.nvidia.com/clara/deploy/ClaraInstallation.html . . Download the clara deploy SDK . . Unzip the file . . Now install the Clara deploy prerequisites. To do this run the bootstrap.sh. This will install kubernetes, helm etc. and their dependencies. . Navigate to the /etc/clara/bootstrap directory and run bootstrap.sh . . Bootstrap.sh had old reference to helm repo . . Had to change to get.helm.sh . . Note: Helm 2 is now unsupported . Tiller pod installation issue: I faced problems successfully running tiller pod . . Tiller image is being sourced from gcr.io . . But the help images now moved to github container registry (ghcr.io) . As per the below deployment manifest, the image will be sourced from gcr.io . . To make the image available, pulled the image manually from ghcr.io and retagged the image name with gcr.io, Along with that changed the imagePullPolicy to Never (from IfNotPresent). . After these steps rerun the bootstrap.sh and pre-requisite should install successfully. . . . . Some helpful links to solve the image mismatch issue: . https://www.programmerall.com/article/273716355/ . https://giters.com/helm/helm/issues/10011 . https://programming.vip/docs/kunernets-uses-helm-to-install-tiller-trampling-pit.html . https://cynthiachuang.github.io/Install-NVIDIA-Clara-Deploy-SDK/ . Install the Clara Deploy CLI . Information of Clara Deploy CLI - https://ngc.nvidia.com/catalog/resources/nvidia:clara:clara_cli . Run wget - . . Move to /usr/bin . . Unzip and chmod . . Verify the Clara CLI is working . . Adding the NGC API key to Clara CLI: . clara config –key &lt;NGC_API_KEY&gt; –orgteam nvidia/clara . Replace &lt;NGC_API_KEY&gt; with your NGC key. . Check the nvcr.io is connected thru docker: . . Pull the clara deploy platform . When started to pull clara platform, error . . My helm is v2, whereas “pull” is recognized in v3. Helm needs to be upgraded. Upgrading helm to 3.6.3, changing the helm_version and helm_checksum and re-executing bootstrap.sh . . . Pods are running and didn’t get recreated: . . Tiller pod got created using kubernetes helm container image 2.15.2 . . There is a version mismatch between client side and server side helm. We will see if this is a problem as we progress. . For now, the `clara pull platform` works: . . Clara service is up as shown by the `helm ls`. Let’s bring the other services up. . . . . . Let’s check the PODs . . All running! . Running inference engine using local input file . Pull a chest xray pipeline . . Keep the model in a common model directory: . . Create a pipeline for inference using the pipeline yaml file and clara create: . . It will give a pipeline ID. . The pipeline is running: . . Feed a input pic in png format to the pipeline by creating a job using the pipeline_id from previous step: . . Start the job manually with the job_id from previous step: . . Create an output destination directory and Download the output files: . . Two file got created, . . CSV file showing the chances of diseases: . . The second file shows the image: . . . We have used Clara deploy successfully to get an inference from an x-ray image! .",
            "url": "https://blog.uplandr.com/2021/08/30/Setup-NVIDIA-Clara-Deploy-for-Medical-Image-Inference.html",
            "relUrl": "/2021/08/30/Setup-NVIDIA-Clara-Deploy-for-Medical-Image-Inference.html",
            "date": " • Aug 30, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Setup Nvidia Clara Train Medical Image",
            "content": "In this post I will go through the process of setting up NVIDIA Clara Train on AWS . I am referring to Brad Genereaux’s blog post to create a NVIDIA Clara based system. . Brad’s blog - https://medium.com/@integratorbrad/how-i-built-a-space-to-train-and-infer-on-medical-imaging-ai-models-part-1-24ec784edb62 . I will also use the NVIDIA Clara official installation guide and various other posts to install and troubleshoot. . Disclaimer: The example shown here is NOT FOR CLINICAL USE and learning purpose only. The models are not FDA approved and not to be used for clinical decision making. . AWS Environment setup . Create an AWS instance with following configuration (taken from NVIDIA official guide): . . Ref: https://docs.nvidia.com/clara/deploy/ClaraInstallation.html#installation-on-a-cloud-service-provider-csp . I will create a spot instance for my environment. P3.8xlarge is an expensive environment, by using a spot instance you can reduce the cost significantly, but it will create some interruption based on spot availability. . You might be ok with using some inexpensive GPU instances like g4dn, but for now I am going with NVIDIA suggested instance(p3) . After creating the spot instance, remote into the AWS server - . . Check that you have a CUDA enabled GPU: . . If nothing comes back from lspci command, then update the PCI hardware database of linux by entering `update-pciids` command and rerun the lspci | grep command. | . Check for the CUDA supported version of linux: . . It is a 64-bit system! . Verify that gcc is installed . . Find out the kernel version of the system . . Before installing CUDA, the kernel header and development package of the same kernel version need to be installed. . . Install CUDA by going to this link and selecting right choices: . https://developer.nvidia.com/cuda-downloads?target_os=Linux . . Reboot the system after you are done with the above steps . . Install Docker . Follow the steps outlined in https://docs.docker.com/engine/install/ubuntu/ . . . Add docker’s official GPG Key . curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg –dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg | . Setup stable repository . echo . “deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu . $(lsb_release -cs) stable” | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null | . Update apt package index . sudo apt-get update . Install docker community edition . sudo apt-get install docker-ce=5:19.03.8~3-0~ubuntu-bionic docker-ce-cli=5:19.03.8~3-0~ubuntu-bionic containerd.io . Verify that Docker is installed . sudo docker run hello-world . Add your user id in Docker user group . sudo usermod -aG docker $USER . Reboot . Sudo reboot now . Install NVIDIA container toolkit . Follow the steps outlined here - . https://github.com/NVIDIA/nvidia-docker . https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker . Setup the stable repository and the GPG key- . distribution=$(. /etc/os-release;echo $ID$VERSION_ID) . &amp;&amp; curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - | . &amp;&amp; curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list | . After updating the package list install the nvidia-docker2 . sudo apt-get update &amp;&amp; sudo apt-get install -y nvidia-docker2 . Restart docker demon . sudo systemctl restart docker . Test by running a base CUDA container . sudo docker run –rm –gpus all nvidia/cuda:11.0-base nvidia-smi . . Configuration of NGC access . Login to NGC (https://ngc.nvidia.com/) and generate API Key and execute the following . mkdir /etc/clara/ngc . cd /etc/clara/ngc . wget https://ngc.nvidia.com/downloads/ngccli_cat_linux.zip &amp;&amp; unzip ngccli_cat_linux.zip &amp;&amp; rm ngccli_cat_linux.zip ngc.md5 &amp;&amp; chmod u+x ngc . Add NGC key in ngc config . ./ngc config set . . Config docker to use NGC token . docker login nvcr.io . . Now Ubuntu is loaded with Docker, NVIDIA docker, NVIDIA container toolkit . This picture shows the logical architecture of the Clara Train (taken from NVIDIA Clara github link given above). . . Get the docker container for NVIDIA Clara Tarin SDK . I am using the latest version available(v4) . docker pull nvcr.io/nvidia/clara-train-sdk:v4.0 . If you face problems with space, make sure to add and resize your drive. . . Restart docker pull if the pull fails for any other reasons. . Successfully pulled clara train docker image: . . Make a folder for experiments and change the ownership to user ubuntu: . . Go inside the clara train SDK by starting docker container in interactive mode: . . Now you are inside the clara train docker container. . Run this command to get a full list of nvidia medical models. . . Create a folder for our 1st model - Chest xray . . Set the parameters for the chosen model . . Download the model. . . This will download the covid-19 chest xray classification model. . The details of the model available at https://ngc.nvidia.com/catalog/models/nvidia:med:clara_train_covid19_exam_ehr_xray . The description of the model as given in the above link: “Description . The ultimate goal of this model is to predict the likelihood that a person showing up in the emergency room will need supplemental oxygen, which can aid physicians in determining the appropriate level of care for patients, including ICU placement.” . . The model is in MMAR format. https://docs.nvidia.com/clara/clara-train-sdk/pt/mmar.html . This is how the model download directory looks like. . . This has all the model weights, scripts and transforms. . Exploring the directory in a bit more details to see the contents . . There you have it, Clara Train is up and running for use. .",
            "url": "https://blog.uplandr.com/2021/08/29/Setup-NVIDIA-Clara-Train-Medical-Image.html",
            "relUrl": "/2021/08/29/Setup-NVIDIA-Clara-Train-Medical-Image.html",
            "date": " • Aug 29, 2021"
        }
        
    
  
    
  
    
        ,"post8": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://blog.uplandr.com/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://blog.uplandr.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://blog.uplandr.com/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}