<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">---</span>
<span class="n">toc</span><span class="p">:</span> <span class="n">true</span>
<span class="n">layout</span><span class="p">:</span> <span class="n">post</span>
<span class="n">description</span><span class="p">:</span> <span class="n">Steps</span> <span class="n">to</span> <span class="n">build</span> <span class="n">a</span> <span class="n">Spleen</span> <span class="n">segmentation</span> <span class="n">app</span> <span class="ow">and</span> <span class="n">deploy</span> <span class="ow">in</span> <span class="n">MONAI</span> <span class="n">Inference</span> <span class="n">Service</span> <span class="p">(</span><span class="n">MIS</span><span class="p">).</span> <span class="n">MIS</span> <span class="ow">is</span> <span class="n">a</span> <span class="n">inference</span> <span class="n">service</span> <span class="n">which</span> <span class="n">can</span> <span class="n">be</span> <span class="n">called</span> <span class="n">over</span> <span class="n">HTTP</span> <span class="n">to</span> <span class="n">execute</span> <span class="n">a</span> <span class="n">MONAI</span> <span class="n">Application</span> <span class="n">Package</span> <span class="p">(</span><span class="n">MAP</span><span class="p">)</span>
<span class="n">categories</span><span class="p">:</span> <span class="p">[</span><span class="n">MLOps</span><span class="p">,</span> <span class="n">MLFlow</span><span class="p">]</span>
<span class="n">title</span><span class="p">:</span> <span class="n">Building</span> <span class="ow">and</span> <span class="n">Deploying</span> <span class="n">A</span> <span class="n">Spleen</span> <span class="n">Segmentation</span> <span class="n">app</span> <span class="n">using</span> <span class="n">MONAI</span> <span class="n">App</span> <span class="n">Packager</span><span class="p">(</span><span class="n">MAP</span><span class="p">)</span> <span class="ow">and</span> <span class="n">MONAI</span> <span class="n">Inference</span> <span class="n">Service</span> <span class="p">(</span><span class="n">MIS</span><span class="p">)</span>
<span class="n">hide</span><span class="p">:</span> <span class="n">false</span>
<span class="n">comments</span><span class="p">:</span> <span class="n">true</span>
<span class="o">---</span>
</code></pre></div></div>

<p>In this post, I will build and deploy a spleen segmentation AI model provider by MONAI, in a AWS environment. The inference service can invoked over HTTP with paylod and the service will produce segmention file for visualization.</p>

<p>We will download spleen segmentation model and data from source in MONAI App Deploy SDK <a href="https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/notebooks/tutorials/03_segmentation_app.html">examples</a>, build the model in an MONAI application package(MAP), and will deploy the MAP using MONAI Inference Service (MIS) for consumption over HTTP. The doumentation is available <a href="https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/notebooks/tutorials/03_segmentation_app.html">here</a>.</p>

<p>The process can be used to deploy any model in torch script using MIS.</p>

<h1 id="1-download-segmentation-model-and-test-data">1. Download Segmentation Model and Test Data</h1>

<p>Run following commands to download the <code class="language-plaintext highlighter-rouge">model.ts</code>, a torch script model for spleen segmentation, and <code class="language-plaintext highlighter-rouge">dcm</code> folder containing the dicom files for testing purpose.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip install gdown
gdown "https://drive.google.com/uc?id=1GC_N8YQk_mOWN02oOzAU_2YDmNRWk--n"
unzip -o "ai_spleen_seg_data_updated_1203.zip"
</code></pre></div></div>

<p>Create a <code class="language-plaintext highlighter-rouge">my_app</code> folder for the application folder structure.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mkdir -p my_app
</code></pre></div></div>

<p>Move python files from MONAI App Deploy SDK <a href="https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/notebooks/tutorials/03_segmentation_app.html">examples</a> to <code class="language-plaintext highlighter-rouge">my_app</code> directory - <code class="language-plaintext highlighter-rouge">__init__.py</code>,  <code class="language-plaintext highlighter-rouge">__main__.py</code>,  <code class="language-plaintext highlighter-rouge">app.py</code>,  <code class="language-plaintext highlighter-rouge">spleen_seg_operator.py</code>
These files are model specific inference operator classes packaged into application class. Application directory required to have specific <code class="language-plaintext highlighter-rouge">.py</code> files for MONAI packager to work.</p>

<p><img src="/images/2022-02-03-deploy-monai-inference-server/image-1.png" alt="" /></p>

<h1 id="2-package-the-segmentation-app">2. Package the Segmentation App</h1>

<p>Go to the directory where <code class="language-plaintext highlighter-rouge">my_app</code> folder and <code class="language-plaintext highlighter-rouge">model.ts</code> is placed and run the following command. This will start building a package (MAP).</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>monai-deploy package -b nvcr.io/nvidia/pytorch:21.11-py3 my_app --tag my_app:latest -m model.ts
</code></pre></div></div>

<p><img src="/images/2022-02-03-deploy-monai-inference-server/image0.png" alt="" /></p>

<p>This will create a docker image of the application</p>

<p><img src="/images/2022-02-03-deploy-monai-inference-server/image-2.png" alt="" /></p>

<h1 id="3-clone-the-monai-inference-servicemis-repositaory">3. Clone the MONAI Inference Service(MIS) Repositaory</h1>

<p>MONAI application packages (MAP) can be deployed in MONAI inference Service (MIS), a RESTful inference service available for consumption over HTTP.</p>

<p>MAPs we build can be deployed on MIS and MIS takes care of underlying infrastructure to enable availablity of the MAPs.</p>

<p>Next, I will cover the steps to install MIS.</p>

<p>We will take next few steps to deploy a MAP using MIS. Helm Charts are utilized to deploy MIS for our MAP.</p>

<p>Clone the MIS repo:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/Project-MONAI/monai-deploy-app-server.git
cd monai-deploy-app-server/components/inference-service


# 4. Build and Containerize the MIS

Build the MIS container:

</code></pre></div></div>
<p>./build.sh</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
# 5. Get MIS Helm charts 

</code></pre></div></div>
<p>wget “https://drive.google.com/uc?id=12uNO1tyqZh1oFkZH41Osliey7TRm-BBG”
unzip -o ‘uc?id=12uNO1tyqZh1oFkZH41Osliey7TRm-BBG’</p>

<p><img src="/images/2022-02-03-deploy-monai-inference-server/image1.png" alt="" /></p>

<h1 id="6-update-helm-charts-with-monai-app-packagemap-information">6. Update Helm Charts with MONAI App Package(MAP) information</h1>

<p>To start the MIS we need to update the helm chart <code class="language-plaintext highlighter-rouge">values.yaml</code>. This is to configure MIS with a MAP.</p>

<h2 id="getting-the-map---application-and-package-manifest-files">Getting the MAP - Application and Package Manifest Files</h2>

<p>To update the helm chart with application related information we need to export the manifest files for the application.
This can be done by executing a <code class="language-plaintext highlighter-rouge">docker run</code> on the MAP image, which will create two json files - <code class="language-plaintext highlighter-rouge">app.json</code> and <code class="language-plaintext highlighter-rouge">pkg.json</code></p>

<p>These two manifest json files will provides parameters needed in updating helms chart <code class="language-plaintext highlighter-rouge">values.yaml</code></p>

<p>Here <code class="language-plaintext highlighter-rouge">my_app:latest</code> is the docker image created by MAP.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mkdir ./export
docker run -it -v "$(pwd)/export/":"/var/run/monai/export/config/" my_app:latest
</code></pre></div></div>

<p><img src="/images/2022-02-03-deploy-monai-inference-server/image2.png" alt="" /></p>

<h2 id="update-helm-charts-with-map-manifests">Update Helm charts with MAP manifests</h2>

<p>Open the values.yaml and update as following</p>

<p><code class="language-plaintext highlighter-rouge">images.monaiInferenceService</code> with MONAI Inference Service image name (monai/inference-service)
<code class="language-plaintext highlighter-rouge">images.monaiInferenceServiceTag</code>with MONAI Inference Service image tag (0.1)
<code class="language-plaintext highlighter-rouge">payloadService.hostVolumePath</code>with path to local directory which will serve as a shared volume between MIS and its PODs
<code class="language-plaintext highlighter-rouge">map.urn</code> with <code class="language-plaintext highlighter-rouge">map-image:tag</code>
<code class="language-plaintext highlighter-rouge">map.entrypoint</code> with data from command in <code class="language-plaintext highlighter-rouge">app.json</code> 
<code class="language-plaintext highlighter-rouge">map.cpu</code> with data from <code class="language-plaintext highlighter-rouge">pkg.json</code>
<code class="language-plaintext highlighter-rouge">map.memory</code> with data from <code class="language-plaintext highlighter-rouge">pkg.json</code>
<code class="language-plaintext highlighter-rouge">map.gpu</code> with data from <code class="language-plaintext highlighter-rouge">pkg.json</code>
<code class="language-plaintext highlighter-rouge">map.inputPath</code> with appending the <code class="language-plaintext highlighter-rouge">input.path</code> with the working-directory in <code class="language-plaintext highlighter-rouge">app.json</code>
<code class="language-plaintext highlighter-rouge">map.outputPath</code> with appending the <code class="language-plaintext highlighter-rouge">output.path</code> with the working-directory in <code class="language-plaintext highlighter-rouge">app.json</code>
<code class="language-plaintext highlighter-rouge">map.modelPath</code> with Model value path within MAP container. Can be obtained from <code class="language-plaintext highlighter-rouge">pkg.json</code> file. Only take the path till folder which hold the models (“/opt/monai/models”)</p>

<h1 id="7-deploy-mis-with-map-using-the-helm-charts">7. Deploy MIS with MAP using the Helm Charts</h1>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>helm install monai-inference-service ./charts/
</code></pre></div></div>

<p><img src="/images/2022-02-03-deploy-monai-inference-server/image4.png" alt="" /></p>

<p>To view the FastAPI generated UI for an instance of MIS, have the service running and then on any browser, navigate to http://HOST_IP:32000/docs</p>

<p><img src="/images/2022-02-03-deploy-monai-inference-server/image5.png" alt="" /></p>

<h1 id="8-test-the-service">8. Test the service</h1>

<p>With MIS running, I can make an inference request to the service using the /upload POST endpoint with the cluster IP and port from running kubectl get svc and a compressed .zip file containing all the input payload files (eg. input.zip)</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Usage:
curl -X 'POST' 'http://&lt;CLUSTER IP&gt;:8000 OR &lt;HOST IP&gt;:32000/upload/' \
    -H 'accept: application/json' \
    -H 'Content-Type: multipart/form-data' \
    -F 'file=@&lt;PATH TO INPUT PAYLOAD ZIP&gt;;type=application/x-zip-compressed' \
    -o output.zip
</code></pre></div></div>

<p><img src="/images/2022-02-03-deploy-monai-inference-server/image6.png" alt="" /></p>

<p>Output segmentation file is in the output foloder.</p>

<p><img src="/images/2022-02-03-deploy-monai-inference-server/image7.png" alt="" /></p>

<p>Open the segmented file in a viewer like <a href="https://www.slicer.org/">3DSlicer</a></p>

<p><img src="/images/2022-02-03-deploy-monai-inference-server/image8.png" alt="" /></p>

<p>It is possible to call the inference service from the FastAPI UI</p>

<p><img src="/images/2022-02-03-deploy-monai-inference-server/image9.png" alt="" /></p>

<p>This post shows how to build and deploy a torch script model using MONAI MAP and MIS. This process can be used to build and deploy other models as well.</p>
